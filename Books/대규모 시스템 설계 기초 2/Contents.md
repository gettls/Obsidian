
# Chapter 6 - 광고 클릭 이벤트 집계

- 광고는 RTB(Real-Time Bidding)로 가치를 산출한다. 즉, 광고를 클릭한 이벤트에 대한 정보를 관리하는게 가장 중요하다.
- 광고 클릭 이벤트를 집계하는 방식으로 DAG(Directed Acyclic Graph) 모델을 제안한다. 맵-리듀스 방식의 프레임워크이다.
	- (아래의 그림과 비슷하다)![[Pasted image 20240926234214.png]]
	- Map: ad-id를 기준으로 집계 노드(=reduce node)에 분산하는 노드
	- Reduce: 각 집계 노드로 분산 처리된 이벤트를 전달받아 처리하는 노드
- 집계 데이터와 원시 데이터 중 어떤 것을 DB에 남겨둬야 할까
	- 둘 다 남기는 게 좋다.
		- **원시 데이터**는 디버깅이나, 데이터 사이언티스트들이 활용하기에 좋고, 집계 결과에 대해 검증을 할 때도 사용할 수 있다.
		- **집계 데이터**는 질의의 성능을 위해서 저장
	- 그렇다면 어떤 DB를 ?
		- 1. 쓰기/읽기 중 어떤 작업이 중심이 되는가 ?
		- 2. 트랜잭션 지원이 필요한가 ?
		- 3. 질의 과정에서 OLAP 함수를 사용해야 하는가 ?
			- 기본적으로 이벤트 데이터는 시계열 데이터다. 그리고 이런 집계 서비스의 경우 읽기/쓰기 연산이 모두 많이 발생한다. 따라서, 쓰기 연산 및 시간 범위 질의에 최적화되어 있는 cassandra나 influxDB가 적합하다.
- 이벤트는 실시간으로 무제한으로 흐른다. 시각마다 데이터가 고루게 들어오지 않기 때문에 동기(Sync) 방식으로 데이터를 전달하게 되면, 트래픽이 튀는 경우 Consumer 측에 부하가 과도하게 쏠릴 수 있다. 따라서, 비동기(Async) 방식으로 데이터를 전달한다.
- 이벤트의 전달 방식? -> Exactly Once!! 
	- 앞서 말했듯, 이벤트 집계 결과에 따라 가격이 달라지기 때문에 중복되어 전송되거나 유실되어서는 안된다. 즉, Exactly Once. 단 한번만 전달이 되어야 한다.
	- offset을 외부 저장소에 기록하는 방식으로 목표를 달성하고자 한다.
		- (Exactly Once 달성을 위한 디자인)![[Pasted image 20240926235959.png]]
- 지난 T 시간동안 가장 많은 클릭 수의 광고 집계 방식
	- tumbling window
		- ![[Pasted image 20240927000438.png]]
		- 비동기 방식을 사용하기 때문에 실질적으로 이벤트가 발생하는 시간과 그 이벤트가 이벤트 브로커를 지나 집계 서비스 노드에서 처리되는 시간이 다를 수 있다. -> 지난 T 시간동안의 클릭 수를 집계해서 순위를 매길 때 문제가 될 수 있다.
			- 뒤의 window와 겹치는 t 시간 만큼을 집계에 허용하는 watermark를 사용하기도 한다.
	- sliding window
		- ![[Pasted image 20240927000450.png]]
			- 일정한 시간 간격마다 새로운 window가 생성된다. -> 요구사항에 적합해서 사용 결정
- 규모 확장
	- 서비스 확장
		- 클릭 이벤트를 발행하는 Producer, 이벤트를 전달하는 Broker, 이벤트를 집계하는 Consumer 측 모두 decoupling이 되어 있어 각각의 노드를 늘리는 것은 문제가 되지 않는다.
	- Broker 확장
		- Partition을 넉넉히 잡아놔야 나중에 Partition을 추가하면서 같은 ad-id가 다른 Partition에 저장되는 문제가 발생하지 않을 수터 있다.
	- Consumer 확장
		- Consumer Group의 수를 리밸런싱하면 그 수를 늘리고 줄이는 작업을 위해 Partition의 소유권이 각각의 Consumer들에게 재조정된다. 
		- 이 작업 중에는 모든 Consumer의 읽기 작업이 중단된다.
		- 이 작업은 Consumer가 많은 경우 많은 시간이 소요되기 때문에 사용량이 많지 않은 시간에 작업을 해야 한다.
- Fault Tolerance
	- 서비스에 장애가 발생하면, 집계 작업 중이던 결과가 유실되기 때문에 브로커에서 데이터를 처음부터 가져와 다시 집계 작업을 해야한다. 
	- 마지막에 가져간 offset을 기준으로 snapshot을 만들어두고, 장애 발생 시 마지막 offset부터 가져가 집계 작업을 이어가면 작업 시간을 줄일 수 있다.

---
# Chapter 7 - 호텔 예약 시스템

```
# 요구사항
1. 5000개 호텔 x 100만 개 객실
2. 평균 객실의 70%가 사용 중, 평균 투숙 기간은 3일
3. 일일 예상 예약 건수 = 100만 * 0.7 / 3 = 233,333 (=~ 240,000)
4. 초당 예약 건수 = 240,000 / 10^5초 =~ 3
```

- RDB 선택 이유
	- RDB는 쓰기보다 읽기 연산에 최적화되어 있음
		- 예약 시스템은 쓰기 연산보다 읽기 연산이 많을 수 밖에 없음 
	- ACID 보장
		- ACID를 보장하지 못하면 이중 청구/예약 문제 등이 발생할 수 있음
	- 데이터 모델링
		- 비즈니스 데이터 구조를 명확하게 표현할 수 있고, 호텔-객실-객실유형 등과 같은 엔티티의 관계를 가장 잘 표현할 수 있음

- 동시성 문제
	- 동시성 문제에 대한 정의
		- 사용자가 [예약] 버튼을 여러 번 누르는 경우
		- 서로 다른 사용자가 동시에 같은 객실을 예약하는 경우 
	- 문제 해결 방안
		- 예약 API를 멱등적으로 설계 
			- 예약 완료 전, [예약 주문서]를 만들어서 `resevation_id`를 발급하고, [예약] API 호출 시 해당 `reservation_id`를 제출하도록 함. -> 해당 `reservation_id`가 있다면 요청은 실패 처리
	- 트랜잭션 보장 방식
		- 비관적 락
			- DB 자원에 락이 걸리는데, 참여하는 레코드가 많아지는 경우 응답 지연을 초래할 수 있고, 데드락이 발생할 수 있는 가능성이 있음
			- 결과적으로 확장성이 좋지 못하고 DB 성능에 치명적인 영향을 끼칠 수도 있음
		- 낙관적 락
			- 테이블에 `Version` 레코드를 추가해서 이에 대한 제약 조건을 활용하는 방안으로, 락을 걸 필요가 없음.
			- 제약 조건 확인은 DB로의 커밋 단계에서 확인을 함. 즉, 사용자는 예약 실패 시 초기 단계부터 프로세스를 다시 거쳐야 하는 문제가 발생함. 
			- 데이터에 대한 경쟁이 치열할 경우 성능이 좋지 못함
		- DB 제약 조건
			- 낙관적 락과 매우 유사한 방식으로, 레코드 자체에 제약조건을 거는 방식
				- ex) `CONSTRAINT 'check_room_count' CHECK (('total_inventory' - total_reserved >= 0))`
			- 장점과 단점은 낙관적 락과 유사함
			- DB에 따라 지원하지 않을 수도 있음

- 확장성
	- QPS가 늘어나는 시나리오에 의해 시스템의 부하가 늘어날 때 가장 먼저 고려해야할 것은, **어떤 곳에 병목이 발생할 수 있을지를 생각하는 것이다.**
	- DB 샤딩
		- 호텔 예약 시스템의 특성 상, `hotel_id`를 기준으로 조회가 시작되기 때문에 `hotel_id`를 기준으로 데이터를 샤딩해도 문제가 되지 않는다. (= `hotel_id % nums(DB)`)
	- 캐싱
		- 잔여 객실에 대한 정보를 캐싱한다. -> 읽기 연산 병목 해결 가능
		- Origin DB와의 일관성 문제 발생 (캐시에는 잔여 객실이 있지만, Origin DB에는 없는 경우)
			- 최종적으로 DB를 확인하면 됨 (간단하게 해결 가능)
				- 예약 시점에 `"다른 사람이 예약을 했습니다."` 문구와 함께 Refresh -> 캐싱 정보 업데이트
			- CDC 같은 솔루션을 사용하는 것도 하나의 방법이 될 수 있음

- 마이크로 서비스간의 일관성
	- 만약 마이크로 서비스들이 독자적인 DB를 사용해야 하는 경우에는 트랜잭션을 관리하는 것이 문제가 될 수 있음
		- 2PC(2-phase commit)
			- 어느 한 노드에 장애가 발생하면, 해당 장애가 복구될 때까지 진행이 중단되기 때문에 성능이 좋지 않음
		- Saga
			- 최종적 일관성에 의존하는 방식. 각 단계가 각각 하나의 트랜잭션이 됨

**2-phase-commit ?**
- DB 노드 밖의 `Transaction Coordinator`라는 새로운 컴포넌트를 도입해서 트랜잭션을 관리한다.
![[Pasted image 20241011113505.png]]![[Pasted image 20241011113459.png]]
- First Phase 
	- `Transaction Coordinator`가 트랜잭션에 참여하는 노드들에 `RequestCommit` 요청을 하고, 이에 대한 응답으로 `OK` or `FAIL` 을 받는다. **모든 노드들에게 응답이 와야 다음 단계를 진행한다.**
- Second Phase
	- 모든 노드들로부터 `OK`응답을 받으면 `COMMIT` 요청을 보내고, `FAIL` 요청이 하나라도 들어오면 `ABORT` 요청을 보낸다

- 단점
	- low latency
		- 모든 노드의 응답을 기다리는 Blocking 방식으로 진행되기 때문에 응답 지연이 발생할 수 있다.
	- SOF(Single Point of Failure)
		- `Transaction Coordinator`가 트랜잭션을 관리하는데, `COMMIT` 요청을 전송하기 직전에 이 컴포넌트에 문제가 생기면 트랜잭션은 중단된 상태로 노드가 회복되기만을 기다려야 한다.
	- participant dependency
		- 트랜잭션의 수행 시간은 트랜잭션에 참여하는 노드의 성능에 좌우된다. 만약, 참여 노드 중 퍼포먼스가 좋지 않은 노드가 단 하나라도 있으면 트랜잭션 시간은 그에 비례해 증가한다.
